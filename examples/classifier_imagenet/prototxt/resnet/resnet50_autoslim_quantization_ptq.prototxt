main_file: "examples/classifier_imagenet/main_quantization.py"
arch: "resnet50"
model_source: TorchVision
log_name: "autoslim_ptq_1G"
debug: false
data: "/data/imagenet/imagenet-torch"
lr: 0.05
epochs: 90
batch_size: 8
workers: 8
print_freq: 50
evaluate: false
pretrained: false
#should use weight,but distillation save model which is not ddp
resume:"logger/distill_best_resnet50_autoslim_flops_1G_77.47.pth"

save_jit_trace: true
seed: 0
gpu_id: ANY
warmup {
  lr_warmup_epochs: 5
  lr_warmup_decay: 0.01
}

lr_scheduler: CosineAnnealingLR

optimizer: SGD
sgd {
  weight_decay: 1e-04
  momentum: 0.9
}

is_subnet:true
auto_slim {
  channel_config_path: "logger/resnet50_search_test_2022-04-06-02:27/search/subnet_992409968.yaml"
}

quantization {
  quantize: true
  quantize_fx: false
  post_training_quantize: true
  backend: TORCH_FBGEMM
  num_calibration_batches: 120
  activation_quantization_observer {
    quantization_method: "quantization_error"
	per_channel: false
	symmetric: false
	reduce_range: true
	dtype: "quint8"
  }
  weight_quantization_observer {
    quantization_method: "minmax"
	per_channel: true
	symmetric: true
	reduce_range: false
	dtype: "qint8"
  }
}
