main_file: "examples/classifier_imagenet/main_distillation.py"
arch: "resnet50"
model_source: TorchVision
log_name: "multi_gpu"
data: "/data/imagenet/imagenet-torch"
debug: false
lr: 0.0500000007450581
epochs: 720
batch_size: 128
workers: 8
print_freq: 50
evaluate: false
pretrained: false
seed: 0
gpu_id: ANY
multi_gpu {
  world_size: 1
  rank: 0
  dist_url: "tcp://127.0.0.1:23457"
  dist_backend: "nccl"
  multiprocessing_distributed: true
}
val_batch_size: 256
warmup {
  lr_warmup_epochs: 5
  lr_warmup_decay: 0.009999999776482582
}
lr_scheduler: CosineAnnealingLR
optimizer: SGD
sgd {
  weight_decay: 9.999999747378752e-06
  momentum: 0.8999999761581421
}
amp: true
distill {
  teacher_model {
    arch: "resnet50d"
    source: Timm
  }
  kl_divergence {
    temperature: 1.0
    reduction: "batchmean"
    loss_weight: 0.699999988079071
  }
}
