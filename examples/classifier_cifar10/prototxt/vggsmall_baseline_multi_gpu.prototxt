main_file: "examples/classifier_cifar10/main.py"
arch: "cifar10_vggsmall"
model_source: Local
log_name: "baseline_multi_gpu"
debug: false
data: "/data/data.cifar10"
lr: 0.02
epochs: 400
batch_size: 400 # 4 gpu
workers: 8
print_freq: 20
evaluate: false
pretrained: false
seed: 0
gpu_id: ANY
multi_gpu {
  world_size: 1
  rank: 0
  dist_url: "tcp://127.0.0.1:23456"
  dist_backend: "nccl"
  multiprocessing_distributed: true
}
warmup {
  lr_warmup_epochs: 10
  lr_warmup_decay: 0.1
}
lr_scheduler: MultiStepLR
multi_step_lr {
  milestones: 80
  milestones: 160
  milestones: 300
  gamma: 0.1
}
optimizer: SGD
sgd {
  weight_decay: 1e-4
  momentum: 0.9
}
